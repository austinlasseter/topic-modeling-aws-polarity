{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA topic modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv('train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>this book goes into great detail on the histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>no chance to say whatsoever the vhs in in ntsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>an example of steinbecks early work with migra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>this game is a long awaited relief to the othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>bought this brought it home wont play apparent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label                                             Review\n",
       "0  __label__1  this book goes into great detail on the histor...\n",
       "1  __label__0  no chance to say whatsoever the vhs in in ntsc...\n",
       "2  __label__1  an example of steinbecks early work with migra...\n",
       "3  __label__1  this game is a long awaited relief to the othe...\n",
       "4  __label__0  bought this brought it home wont play apparent..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the dataframe into positive and negative reviews\n",
    "negative = documents[documents['Label']=='__label__0'].sample(25000)\n",
    "positive = documents[documents['Label']=='__label__1'].sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple tokenizer (NLTK won't be available to us later on, in our Lambda function)\n",
    "\n",
    "def simple_tokenizer(input_text):\n",
    "    REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(=)|(`)\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)|(\\n)|(\\t)\")\n",
    "    tokens = REPLACE_NO_SPACE.sub(\"\", input_text.lower())\n",
    "    tokens = REPLACE_WITH_SPACE.sub(\" \", tokens) # note that blazing text expects space-separated tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 15 keywords for each topic\n",
    "\n",
    "def show_topics(vectorizer, lda_model, n_words):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topics(dataframe):\n",
    "    # extract the reviews\n",
    "    documents=dataframe['Review'].values\n",
    "    # tokenize the text\n",
    "    tok_documents = [simple_tokenizer(doc) for doc in documents]\n",
    "    # vectorize with TF-IDF\n",
    "    no_features = 1000\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(tok_documents)\n",
    "    # extract feature names\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    # Instantiate the LDA class object from scikitlearn\n",
    "    lda = LatentDirichletAllocation(n_components=10, \n",
    "                                    max_iter=5, \n",
    "                                    learning_method='online', \n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)\n",
    "\n",
    "    # Fit our LDA model onto the vectorized text data\n",
    "    lda.fit(tfidf)\n",
    "    # column names\n",
    "    topicnames = ['Topic' + str(i) for i in range(lda.n_components)]\n",
    "    # Topic-Keyword Matrix\n",
    "    df_topic_keywords = pd.DataFrame(lda.components_)\n",
    "    # Assign Column and Index\n",
    "    df_topic_keywords.columns = tfidf_vectorizer.get_feature_names()\n",
    "    df_topic_keywords.index = topicnames\n",
    "    # get the top 15 words\n",
    "    topic_keywords = show_topics(vectorizer=tfidf_vectorizer, lda_model=lda, n_words=15)\n",
    "    # Topic - Keywords Dataframe\n",
    "    df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "    df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "    df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "    # Extract topic probability scores with LDA Transform\n",
    "    topic_probability_scores = lda.transform(tfidf)\n",
    "    # create a dataframe with our results\n",
    "    df_final = pd.DataFrame(documents, columns=['text'])\n",
    "    dom_topics=[np.argmax(topic_probability_scores[index]) for index in range(len(topic_probability_scores))]\n",
    "    df_final['pred_topic']=dom_topics\n",
    "    df_final['topic_words']=df_final['pred_topic'].apply(lambda x: df_topic_keywords.iloc[x].values.tolist())\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to our datasets\n",
    "final_pos = create_topics(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_neg = create_topics(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "      <th>topic_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i only read the first 2 chapters of this book ...</td>\n",
       "      <td>__label____label____label____label__8</td>\n",
       "      <td>[book, read, story, books, characters, like, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have to start by saying i love this movie an...</td>\n",
       "      <td>__label____label____label____label__7</td>\n",
       "      <td>[movie, film, watch, movies, dvd, bad, just, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i started this book a gift threw it across the...</td>\n",
       "      <td>__label____label____label____label__8</td>\n",
       "      <td>[book, read, story, books, characters, like, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poor quality lasted for less than a month even...</td>\n",
       "      <td>__label____label____label____label__6</td>\n",
       "      <td>[product, use, bought, just, months, used, buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im sorry to say that this book almost put me t...</td>\n",
       "      <td>__label____label____label____label__8</td>\n",
       "      <td>[book, read, story, books, characters, like, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  i only read the first 2 chapters of this book ...   \n",
       "1  i have to start by saying i love this movie an...   \n",
       "2  i started this book a gift threw it across the...   \n",
       "3  poor quality lasted for less than a month even...   \n",
       "4  im sorry to say that this book almost put me t...   \n",
       "\n",
       "                                   Label  \\\n",
       "0  __label____label____label____label__8   \n",
       "1  __label____label____label____label__7   \n",
       "2  __label____label____label____label__8   \n",
       "3  __label____label____label____label__6   \n",
       "4  __label____label____label____label__8   \n",
       "\n",
       "                                         topic_words  \n",
       "0  [book, read, story, books, characters, like, r...  \n",
       "1  [movie, film, watch, movies, dvd, bad, just, l...  \n",
       "2  [book, read, story, books, characters, like, r...  \n",
       "3  [product, use, bought, just, months, used, buy...  \n",
       "4  [book, read, story, books, characters, like, r...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the results\n",
    "final_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n",
      "(5000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(final_neg[:20000].shape)\n",
    "print(final_neg[20000:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_bt(df1, output_train, output_valid):\n",
    "    # Prefix the index-ed label with __label__\n",
    "    df = df1.copy()\n",
    "    df.rename(columns={'pred_topic':'Label'}, inplace=True)\n",
    "    df.drop(['topic_words'], axis=1, inplace=True)\n",
    "#     df['Label']=df['Label'].apply(lambda row: \"__label__\" +  str(row) )\n",
    "    \n",
    "    # convert the transformed dataframe into a list\n",
    "    transformed_train = np.array(df[:20000]).tolist()\n",
    "    transformed_validation = np.array(df[20000:]).tolist()\n",
    "\n",
    "    # write to csv file (for blazingtext)\n",
    "    with open(output_train, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n') # notice the delimiter.\n",
    "        csv_writer.writerows(transformed_train)\n",
    "\n",
    "    # write to csv file (for blazingtext)\n",
    "    with open(output_valid, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n') # notice the delimiter.\n",
    "        csv_writer.writerows(transformed_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "prep_for_bt(final_neg, 'topics_negative.train', 'topics_negative.validation')\n",
    "prep_for_bt(final_neg, 'topics_positive.train', 'topics_positive.validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of the top 10 words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_topics = final_pos.groupby('Label')[['topic_words']].max()\n",
    "pos_topics.to_csv('top10words_pos.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_topics = final_neg.groupby('Label')[['topic_words']].max()\n",
    "neg_topics.to_csv('top10words_neg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['cold', 'memory', 'program', 'mouse', 'shes', 'period', 'crazy', 'minor', 'relate', 'wall', 'historical', 'software', 'war', 'outside', 'role'])],\n",
       "       [list(['condition', 'arrived', 'product', 'amazon', 'expected', 'service', 'order', 'delivery', 'ordered', 'quickly', 'price', 'came', 'great', 'headphones', 'exactly'])],\n",
       "       [list(['book', 'information', 'great', 'informative', 'helpful', 'easy', 'guide', 'questions', 'useful', 'reference', 'text', 'good', 'excellent', 'recommend', 'read'])],\n",
       "       [list(['movie', 'film', 'dvd', 'movies', 'watch', 'great', 'season', 'series', 'seen', 'watching', 'good', 'best', 'love', 'acting', 'tv'])],\n",
       "       [list(['book', 'read', 'books', 'story', 'reading', 'life', 'characters', 'great', 'good', 'author', 'written', 'like', 'time', 'really', 'people'])],\n",
       "       [list(['video', 'workout', 'everyday', 'speakers', 'white', 'tape', 'ok', 'gone', 'videos', 'green', 'body', 'hooked', 'black', 'blue', 'rich'])],\n",
       "       [list(['cd', 'album', 'music', 'songs', 'song', 'like', 'great', 'best', 'love', 'good', 'listen', 'just', 'band', 'rock', 'heard'])],\n",
       "       [list(['la', 'que', 'el', 'master', 'performances', 'plenty', 'typical', 'enjoyable', 'production', 'cast', 'brilliant', 'super', 'living', 'added', 'sets'])],\n",
       "       [list(['use', 'great', 'product', 'good', 'just', 'easy', 'price', 'like', 'works', 'bought', 'nice', 'little', 'used', 'time', 'really'])],\n",
       "       [list(['game', 'book', 'movie', 'love', 'old', 'great', 'fun', 'story', 'really', 'like', 'kids', 'loves', 'good', 'year', 'loved'])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_topics.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['book', 'information', 'books', 'author', 'read', 'guide', 'edition', 'useful', 'errors', 'good', 'text', 'learn', 'does', 'pages', 'written'])],\n",
       "       [list(['cd', 'album', 'music', 'songs', 'like', 'song', 'sound', 'band', 'just', 'good', 'listen', 'sounds', 'dont', 'rock', 'voice'])],\n",
       "       [list(['product', 'work', 'use', 'like', 'does', 'software', 'windows', 'bought', 'program', 'did', 'tried', 'buy', 'dont', 'just', 'good'])],\n",
       "       [list(['game', 'games', 'play', 'video', 'toy', 'dont', 'money', 'fun', 'like', 'graphics', 'just', 'playing', 'really', 'kids', 'buy'])],\n",
       "       [list(['amazon', 'product', 'received', 'item', 'ordered', 'phone', 'sent', 'return', 'order', 'service', 'dvd', 'work', 'did', 'buy', 'refund'])],\n",
       "       [list(['kindle', 'hair', 'points', 'rate', 'sleep', 'eyes', 'guys', 'michael', 'face', 'guy', 'sold', 'people', 'lines', 'skin', 'body'])],\n",
       "       [list(['product', 'use', 'bought', 'just', 'months', 'used', 'buy', 'time', 'work', 'plastic', 'like', 'good', 'dont', 'got', 'broke'])],\n",
       "       [list(['movie', 'film', 'watch', 'movies', 'dvd', 'bad', 'just', 'like', 'acting', 'time', 'good', 'really', 'watching', 'dont', 'story'])],\n",
       "       [list(['book', 'read', 'story', 'books', 'characters', 'like', 'reading', 'just', 'author', 'written', 'writing', 'really', 'plot', 'good', 'time'])],\n",
       "       [list(['children', 'child', 'country', 'parents', 'wants', 'modern', 'american', 'market', 'thank', 'wife', 'accurate', 'include', 'war', 'history', 'man'])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_topics.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
